#+TITLE: MERLIN Instance Generation

* DONE integrate correlated rewards into neural nets
CLOSED: [2014-02-13 Thu 11:53]
Generate and train a second neural network, this one predicting
state+action->reward

* TODO write tests for new code

* TODO implement the garnet generator

* TODO separate interfaces for transitions/rewards/states
Need three separate parameters: (1) the type of transition dynamics to use, (2)
the type of state-value function to use, and (3) the type of reward assignment
to use. Should be able to mix and match them.

* DONE assign state-values by random walks
CLOSED: [2014-02-20 Thu 17:24]
Currently state values are assigned by simply ordering the states from 1 to N.
It would be better if the state values were assigned to the states in the order
that states were encountered.
** Possible implementation strategy
1. Pick a start state and take a random walk along unvisited nodes. Record the
   visited nodes in a list, and after no more steps can be made, generate a
   landscape of length $k$, where $k$ is the length of the walk.
2. Remove the $k$ visited nodes from the global node list
3. Pick a new unvisited starting node and repeat the process until all nodes
   have been visited.

* DONE specify output files on the command line rather than hard coding them
CLOSED: [2014-02-13 Thu 16:03]

* TODO allow generation of more than one fuzzed network at a time
Should pass a command line argument specifying the number of alternatives to
generate, and a stem for the output file name. It should then write out that
many files, stem01.net, stem02.net, etc.

* TODO change other problem types to specify an output file instead of stdout
  
* TODO switch to scikit-learn from pybrain

* TODO switch from classification to regression
Use a separate regression model for every output variable

* DONE ditch separate state-value/action-value maps
CLOSED: [2014-02-15 Sat 17:26]
Just augment the graph directly with annotations
 
* TODO give better control over range of action values

* TODO allow unused state variables
Should be able to generate state vectors in which not all of the values are
used in the dynamics and/or rewards.  
